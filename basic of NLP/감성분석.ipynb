{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  감정분석\n",
    "- 나이브 베이즈 분류를 이용한 감정분석\n",
    "\n",
    "**나이브 베이즈 분류**\n",
    "> 기계 학습 분야에서, '나이브 베이즈 분류(Naïve Bayes Classification)는 특성들 사이의 독립을 가정하는 베이즈 정리를 적용한 확률 분류기의 일종으로 1950년대 이후 광범위하게 연구되고 있다.\n",
    "통계 및 컴퓨터 과학 문헌에서, 나이브 베이즈는 단순 베이즈, 독립 베이즈를 포함한 다양한 이름으로 알려져 있으며, 1960년대 초에 텍스트 검색 커뮤니티에 다른 이름으로 소개되기도 하였다.\n",
    "나이브 베이즈 분류는 텍스트 분류에 사용됨으로써 문서를 여러 범주 (예: 스팸, 스포츠, 정치) 중 하나로 판단하는 문제에 대한 대중적인 방법으로 남아있다. 또한, 자동 의료 진단 분야에서의 응용사례를 보면, 적절한 전처리를 하면 더 진보된 방법들 (예: 서포트 벡터 머신 (Support Vector Machine))과도 충분한 경쟁력을 보임을 알 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bigdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나이브 베이즈 분류기는 지도학습이라서 정답을 알려주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('i like you', 'pos'),\n",
    "        ('i hate you', 'neg'),\n",
    "        ('you like me', 'neg'),\n",
    "        ('i like her', 'pos')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 말뭉치 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = train[0]\n",
    "word_tokenize(sentence[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'like',\n",
       " 'you',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'you',\n",
       " 'you',\n",
       " 'like',\n",
       " 'me',\n",
       " 'i',\n",
       " 'like',\n",
       " 'her']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set 명령을 안 할 경우\n",
    "[word.lower() for sentence in train for word in word_tokenize(sentence[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'me', 'you'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 에서 하나씩 sentence를 받아오고 senetence의 [0] 첫번째를 토큰화해서 워드로 받아오고 이걸 소문자로 변형\n",
    "# 집합으로 받아와서 중복되지 않게 가져옴.\n",
    "\n",
    "all_words  = set(\n",
    "    word.lower() for sentence in train for word in word_tokenize(sentence[0])\n",
    ")\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i like you', 'pos')\n",
      "('i hate you', 'neg')\n",
      "('you like me', 'neg')\n",
      "('i like her', 'pos')\n"
     ]
    }
   ],
   "source": [
    "for x in train:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'me': False,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'i': True,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'pos'),\n",
       " ({'me': False,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'i': True,\n",
       "   'like': False,\n",
       "   'hate': True},\n",
       "  'neg'),\n",
       " ({'me': True,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'i': False,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'neg'),\n",
       " ({'me': False,\n",
       "   'you': False,\n",
       "   'her': True,\n",
       "   'i': True,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t =  [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train ]\n",
    "t\n",
    "\n",
    "# 이때 t에서 위의 두개를 살펴보면 you 가 둘다 들어가있는 문장이 각각 pos, neg로 50%확률이다.\n",
    "# 이렇게 독립적으로 사건이 일어나는 것을 나이브 베이즈 특성이라 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈에서는 sklearn이 아니라 nltk 를 사용\n",
    "#이렇게 각 단어별로 독립적으로 확률을 계산하기 때문에 naive하다고 한다.\n",
    "\n",
    "clf = nltk.NaiveBayesClassifier.train(t)\n",
    "clf.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'me': False,\n",
       " 'you': False,\n",
       " 'her': False,\n",
       " 'i': True,\n",
       " 'like': True,\n",
       " 'hate': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence =  'i like MeRui'\n",
    "test_sent_featues = {\n",
    "    word.lower() : (word in word_tokenize(test_sentence.lower())) for word in all_words\n",
    "}\n",
    "test_sent_featues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(test_sent_featues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글\n",
    "- 한글은 형태소 분석을 해야함\n",
    "- Okt 는 konlpy 라는 파이썬 라이브러리에서 제공하는 형태소 분석기 중 하나\n",
    "- Open Korean Text 의 약자로, 원래는 트위터에서 개발한 한국어 형태소 분석기\n",
    "- 형태소 분석, 품사태깅, 명사추출, 어근 추출과 같은 기능을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**❌형태소 분석 없이 진행한 경우**\n",
    "- 제대로 감성분석이 되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    ('메리가 좋아','pos'),\n",
    "    ('고양이도 좋아','pos'),\n",
    "    ('난 수업이 지루해','neg'),\n",
    "    ('메리는 이쁜 고양이야','pos'),\n",
    "    ('난 마치고 메리랑 놀거야','pos'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(\n",
    "    word for sentence in train for word in word_tokenize(sentence[0])\n",
    ")\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'고양이도': False,\n",
       "   '메리는': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '이쁜': False,\n",
       "   '마치고': False,\n",
       "   '메리가': True,\n",
       "   '놀거야': False,\n",
       "   '메리랑': False,\n",
       "   '난': False,\n",
       "   '지루해': False,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이도': True,\n",
       "   '메리는': False,\n",
       "   '좋아': True,\n",
       "   '고양이야': False,\n",
       "   '이쁜': False,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '놀거야': False,\n",
       "   '메리랑': False,\n",
       "   '난': False,\n",
       "   '지루해': False,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이도': False,\n",
       "   '메리는': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '이쁜': False,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '놀거야': False,\n",
       "   '메리랑': False,\n",
       "   '난': True,\n",
       "   '지루해': True,\n",
       "   '수업이': True},\n",
       "  'neg'),\n",
       " ({'고양이도': False,\n",
       "   '메리는': True,\n",
       "   '좋아': False,\n",
       "   '고양이야': True,\n",
       "   '이쁜': True,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '놀거야': False,\n",
       "   '메리랑': False,\n",
       "   '난': False,\n",
       "   '지루해': False,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이도': False,\n",
       "   '메리는': False,\n",
       "   '좋아': False,\n",
       "   '고양이야': False,\n",
       "   '이쁜': False,\n",
       "   '마치고': True,\n",
       "   '메리가': False,\n",
       "   '놀거야': True,\n",
       "   '메리랑': True,\n",
       "   '난': True,\n",
       "   '지루해': False,\n",
       "   '수업이': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word : (word in word_tokenize(x[0])) for word in all_words},x[1]) for x in train ]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(t)\n",
    "clf.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도': False,\n",
       " '메리는': False,\n",
       " '좋아': False,\n",
       " '고양이야': False,\n",
       " '이쁜': False,\n",
       " '마치고': False,\n",
       " '메리가': False,\n",
       " '놀거야': True,\n",
       " '메리랑': True,\n",
       " '난': True,\n",
       " '지루해': False,\n",
       " '수업이': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀거야'\n",
    "\n",
    "test_sent_featues = {word.lower(): word in word_tokenize(test_sentence.lower()) for word in all_words}\n",
    "test_sent_featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(test_sent_featues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⭕형태소 분석을 한 경우**\n",
    "- 형태소 분석을 한 후 품사를 단어 뒤에 붙여넣도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm = True, stem = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n",
       " (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n",
       " (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메리/Noun',\n",
       " '가/Josa',\n",
       " '좋다/Adjective',\n",
       " '고양이/Noun',\n",
       " '도/Josa',\n",
       " '좋다/Adjective',\n",
       " '난/Noun',\n",
       " '수업/Noun',\n",
       " '이/Josa',\n",
       " '지루하다/Adjective',\n",
       " '메리/Noun',\n",
       " '는/Josa',\n",
       " '이쁘다/Adjective',\n",
       " '고양이/Noun',\n",
       " '야/Josa',\n",
       " '난/Noun',\n",
       " '마치/Noun',\n",
       " '고/Josa',\n",
       " '메리/Noun',\n",
       " '랑/Josa',\n",
       " '놀다/Verb']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exist(docs):\n",
    "    return {word : (word in set(docs)) for word in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리/Noun': True,\n",
       "   '가/Josa': True,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': True,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': True,\n",
       "   '이/Josa': True,\n",
       "   '지루하다/Adjective': True,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'neg'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': True,\n",
       "   '이쁘다/Adjective': True,\n",
       "   '야/Josa': True,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': True,\n",
       "   '고/Josa': True,\n",
       "   '랑/Josa': True,\n",
       "   '놀다/Verb': True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xy = [(term_exist(d),c) for d,c in train_docs]\n",
    "train_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  난/Noun = True              neg : pos    =      2.5 : 1.0\n",
      "                 메리/Noun = False             neg : pos    =      2.5 : 1.0\n",
      "                고양이/Noun = False             neg : pos    =      1.5 : 1.0\n",
      "            좋다/Adjective = False             neg : pos    =      1.5 : 1.0\n",
      "                  가/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  고/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                 놀다/Verb = False             neg : pos    =      1.1 : 1.0\n",
      "                  는/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  도/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  랑/Josa = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(train_xy)\n",
    "clf.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('난', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('메리', 'Noun'),\n",
       " ('랑', 'Josa'),\n",
       " ('놀거야', 'Verb')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀거야'\n",
    "\n",
    "test_docs =pos_tagger.pos(test_sentence)\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('난', 'Noun'): False,\n",
       " ('수업', 'Noun'): False,\n",
       " ('이', 'Josa'): False,\n",
       " ('마치', 'Noun'): False,\n",
       " ('면', 'Josa'): False,\n",
       " ('메리', 'Noun'): False,\n",
       " ('랑', 'Josa'): False,\n",
       " ('놀거야', 'Verb'): False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_featues = {word : (word in tokens) for word in test_docs}\n",
    "test_sent_featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(test_sent_featues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
